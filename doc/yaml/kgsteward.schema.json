{
  "$defs": {
    "CurlRiotChunkStoreUrlLoader": {
      "properties": {
        "method": {
          "const": "curl_riot_chunk_store",
          "description": "URL are downloaded using curl to a temporary file, which is then loaded with `riot_chunk_store` method.",
          "title": "curl/riot/store URL loader",
          "type": "string"
        },
        "tmp_dir": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": "/tmp",
          "description": "temporary directory",
          "title": "temporary directory"
        },
        "size": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 100000000,
          "description": "chunk size",
          "title": "chunk size"
        }
      },
      "required": [
        "method"
      ],
      "title": "CurlRiotChunkStoreUrlLoader",
      "type": "object"
    },
    "DatasetConf": {
      "properties": {
        "name": {
          "description": "Mandatory name of a dataset record.",
          "pattern": "^[a-zA-Z]\\w{0,31}$",
          "title": "Short name of a dataset record",
          "type": "string"
        },
        "context": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The IRI of the target context. If missing, it will be built by concataining `context_base_IRI` and `name`.",
          "title": "Full IRI of a context/named graph"
        },
        "parent": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "A list of dataset names to declare dependency between dataset records. Updating the parent datset will provoke the update of its children, unless it is frozen.",
          "title": "Parent(s) of a dataset record"
        },
        "frozen": {
          "anyOf": [
            {
              "type": "boolean"
            },
            {
              "type": "null"
            }
          ],
          "default": false,
          "description": "Frozen record, can only be updated explicitely with the `-d <name>` option. The option `-C` has no effect",
          "title": "Frozen dataset record"
        },
        "system": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "A list of system command. This is a simple convenience provided by kgsteward, which is not meant to be a replacement for serious Make-like system as for example git/dvc.",
          "title": "UNIX system command(s)"
        },
        "file": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "List of files containing RDF data. Wildcards `*` can be used. The strategy used to load these files will depends on if a file server is used (see `file_server_port` option`). With GraphDB, there might be a maximum file size (200 MB by default (?)) and compressed files may not be supported. Using a file server, these limitations are overcome, but see the security warning described above.",
          "title": "Load RDF from file(s)"
        },
        "url": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "List of url from which to load RDF data",
          "title": "Load RDF from URL(s)"
        },
        "stamp": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "List of file paths or URLs to which last modification dates will used. The file contents are ignored. Wildcards `*` can be used.",
          "title": "Stamp file(s)"
        },
        "replace": {
          "anyOf": [
            {
              "additionalProperties": {
                "type": "string"
              },
              "type": "object"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Dictionary to perform string substitution in SPARQL queries from `update` list. Of uttermost interest is the `${TARGET_GRAPH_CONTEXT}` which permit to restrict updates to the current context.",
          "title": "String substitution in SPARQL update(s)"
        },
        "update": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "List of files containing SPARQL update commands. Wildcards are not recommended here, as the order of the SPARQL updates possibly matters!",
          "title": "SPARQL update file(s)"
        },
        "zenodo": {
          "anyOf": [
            {
              "items": {
                "type": "integer"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Do not use! Fetch turtle files from zenodo. This is a completely ad hoc command developed for ENPKG, that will be suppressed sooner or later.",
          "title": "Ignore me"
        },
        "special": {
          "anyOf": [
            {
              "items": {
                "$ref": "#/$defs/SpecialEnum"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "A list of special dataset records. Supported values are \"sib_swiss_void\".",
          "title": "Special dataset"
        }
      },
      "required": [
        "name"
      ],
      "title": "DatasetConf",
      "type": "object"
    },
    "FusekiConf": {
      "additionalProperties": true,
      "properties": {
        "brand": {
          "const": "fuseki",
          "description": "String identifying the server brand. One of 'graphdb', 'rdf4j', 'fuseki'",
          "title": "Fuseki brand",
          "type": "string"
        },
        "location": {
          "description": "URL of the server. The SPARQL endpoint locations for queries, updates and stores are specific to a server brand. Fuseki has location 'http://localhost:3030' by default",
          "title": "Server URL",
          "type": "string"
        },
        "repository": {
          "description": "The name of the 'repository' (GraphDB/RDF4J naming) or 'dataset' (fuseki) in the triplestore.",
          "pattern": "^\\w{1,32}$",
          "title": "Repository ID",
          "type": "string"
        },
        "file_server_port": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 0,
          "description": "Integer, `0` by default, i.e. the file server is turned off. When set to a positive integer, say `8000`, local files will be exposed through a temporary HTTP server and loaded from it. Support for different RDF file types and their compressed version depend on the tripelstore. The benefit is the that RDF data from `file` are processed with the same protocol as those supplied remotely through `url`. Essentially for GraphDB, file-size limits are suppressed and compressed formats are supported. Beware that the used python-based server is potentially insecure (see [here](https://docs.python.org/3/library/http.server.html) for details). This should however pose no real treat if used on a personal computer or on a server that is behind a firewall.",
          "title": "file_server_port"
        }
      },
      "required": [
        "brand",
        "location",
        "repository"
      ],
      "title": "FusekiConf",
      "type": "object"
    },
    "GraphDBConf": {
      "additionalProperties": true,
      "properties": {
        "brand": {
          "const": "graphdb",
          "description": "String identifying the server brand. One of 'graphdb', 'rdf4j', 'fuseki'",
          "title": "GraphDB brand",
          "type": "string"
        },
        "location": {
          "description": "URL of the server. The SPARQL endpoint locations for queries, updates and stores are specific to a server brand. GraphDB has location 'http://localhost:7200' by default",
          "title": "Server URL",
          "type": "string"
        },
        "server_config": {
          "description": "Filename with the triplestore configuration, possibly a turtle file. This file can be saved from the UI interface of RDF4J/GraphDB after a first repository was created interactively, thus permitting to reproduce the repository configuration elsewhere. This file is used by the `-I` and `-F` options. Beware that the repository ID could be hard-coded in the config file and should be maintained in sync with `repository`.",
          "title": "Server config file",
          "type": "string"
        },
        "file_server_port": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "Integer, `0` by default, i.e. the file server is turned off. When set to a positive integer, say `8000`, local files will be exposed through a temporary HTTP server and loaded from it. Support for different RDF file types and their compressed version depend on the tripelstore. The benefit is the that RDF data from `file` are processed with the same protocol as those supplied remotely through `url`. Essentially for GraphDB, file-size limits are suppressed and compressed formats are supported. Beware that the used python-based server is potentially insecure (see [here](https://docs.python.org/3/library/http.server.html) for details). This should however pose no real treat if used on a personal computer or on a server that is behind a firewall.",
          "title": "file_server_port"
        },
        "username": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The name of a user with write-access rights in the triplestore.",
          "title": "Username"
        },
        "password": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "The password of a user with write-access rights to the triplestore. It is recommended that the value of this variable is passed trough an environment variable. By this way the password is not stored explicitely in the config file. Alternatively `?` can be used and the password will be asked interactively at run time.",
          "title": "Password"
        },
        "prefixes": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "A list of Turtle files from which prefix definitions can be obtained.         This list will used to update the namespace definitions in GraphDB and RDF4J.         Otherwise it is ignored",
          "title": "GraphDB namespace"
        },
        "repository": {
          "description": "The name of the 'repository' (GraphDB/RDF4J naming) or 'dataset' (fuseki) in the triplestore.",
          "pattern": "^\\w{1,32}$",
          "title": "Repository ID",
          "type": "string"
        }
      },
      "required": [
        "brand",
        "location",
        "server_config",
        "repository"
      ],
      "title": "GraphDBConf",
      "type": "object"
    },
    "HttpServerFileLoader": {
      "properties": {
        "method": {
          "const": "http_server",
          "description": "Files are exposed through a temporary HTTP server. This is the recommended method with GraphDB.",
          "title": "HTTP file server",
          "type": "string"
        },
        "port": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 8000,
          "description": "Integer, `0` by default, i.e. the file server is turned off. When set to a positive integer, say `8000`, local files will be exposed through a temporary HTTP server and loaded from it. Support for different RDF file types and their compressed version depend on the tripelstore. The benefit is the that RDF data from `file` are processed with the same protocol as those supplied remotely through `url`. Essentially for GraphDB, file-size limits are suppressed and compressed formats are supported. Beware that the used python-based server is potentially insecure (see [here](https://docs.python.org/3/library/http.server.html) for details). This should however pose no real treat if used on a personal computer or on a server that is behind a firewall.",
          "title": "file_server_port"
        }
      },
      "required": [
        "method"
      ],
      "title": "HttpServerFileLoader",
      "type": "object"
    },
    "QueryConf": {
      "properties": {
        "name": {
          "description": "Mandatory name of a set queries",
          "pattern": "^[a-zA-Z]\\w{0,31}$",
          "title": "Short name of a query set",
          "type": "string"
        },
        "system": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "A list of system command. This is a simple convenience provided by kgsteward, which is not meant to be a replacement for serious Make-like system as for example git/dvc.",
          "title": "UNIX system command(s)"
        },
        "test": {
          "anyOf": [
            {
              "$ref": "#/$defs/TestConf"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "assert nothing/something",
          "title": "Assertion to be tested"
        },
        "public": {
          "anyOf": [
            {
              "type": "boolean"
            },
            {
              "type": "null"
            }
          ],
          "default": true,
          "description": "no description",
          "title": "Should query be published"
        },
        "file": {
          "anyOf": [
            {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "description": "List of files containing one SPARQL query each. Wildcards `*` can be used, and implied file names will be sorted alphabetically. The file name of each file is interpreted as the query label. In each file, lines starting with \"#\" are considered as the query documentation (comment)",
          "title": "Load queries from files"
        }
      },
      "required": [
        "name"
      ],
      "title": "QueryConf",
      "type": "object"
    },
    "RDF4JConf": {
      "additionalProperties": true,
      "properties": {
        "brand": {
          "const": "rdf4j",
          "description": "String identifying the server brand. One of 'graphdb', 'rdf4j', 'fuseki'",
          "title": "RDF4J brand",
          "type": "string"
        },
        "location": {
          "description": "URL of the server. The SPARQL endpoint locations for queries, updates and stores are specific to a server brand. RDF4J has location 'http://localhost:8080' by default",
          "title": "Server URL",
          "type": "string"
        },
        "repository": {
          "description": "The name of the 'repository' (GraphDB/RDF4J naming) or 'dataset' (fuseki) in the triplestore.",
          "pattern": "^\\w{1,32}$",
          "title": "Repository ID",
          "type": "string"
        },
        "file_server_port": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 0,
          "description": "Integer, `0` by default, i.e. the file server is turned off. When set to a positive integer, say `8000`, local files will be exposed through a temporary HTTP server and loaded from it. Support for different RDF file types and their compressed version depend on the tripelstore. The benefit is the that RDF data from `file` are processed with the same protocol as those supplied remotely through `url`. Essentially for GraphDB, file-size limits are suppressed and compressed formats are supported. Beware that the used python-based server is potentially insecure (see [here](https://docs.python.org/3/library/http.server.html) for details). This should however pose no real treat if used on a personal computer or on a server that is behind a firewall.",
          "title": "file_server_port"
        }
      },
      "required": [
        "brand",
        "location",
        "repository"
      ],
      "title": "RDF4JConf",
      "type": "object"
    },
    "RiotChunkStoreFileLoader": {
      "properties": {
        "method": {
          "const": "riot_chunk_store",
          "description": "riot_chunk_store",
          "title": "riot/store file loader",
          "type": "string"
        },
        "size": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": 100000000,
          "description": "chunk size",
          "title": "chunk size"
        }
      },
      "required": [
        "method"
      ],
      "title": "RiotChunkStoreFileLoader",
      "type": "object"
    },
    "SparqlFileLoader": {
      "properties": {
        "method": {
          "const": "sparql_load",
          "description": "Files are loaded using the SPARQL update statement: \"LOAD <file://<file-path> INTO...\". This strategy is likely to failed for large files, or worst silently truncate them.",
          "title": "sparql file loader",
          "type": "string"
        }
      },
      "required": [
        "method"
      ],
      "title": "SparqlFileLoader",
      "type": "object"
    },
    "SparqlUrlLoader": {
      "properties": {
        "method": {
          "const": "sparql_load",
          "description": "URL are loaded using the SPARQL update statement: \"LOAD <url> INTO...\". This strategy could fail for large files, or worst silently truncate them.",
          "title": "direct url loader",
          "type": "string"
        }
      },
      "required": [
        "method"
      ],
      "title": "SparqlUrlLoader",
      "type": "object"
    },
    "SpecialEnum": {
      "enum": [
        "sib_swiss_void",
        "sib_swiss_prefix",
        "sib_swiss_query"
      ],
      "title": "SpecialEnum",
      "type": "string"
    },
    "StoreFileLoader": {
      "properties": {
        "method": {
          "const": "file_store",
          "description": "Files are loaded using the graph store protocol. This strategy is likely to failed for large files, or worst silently truncate them.",
          "title": "store file loader",
          "type": "string"
        }
      },
      "required": [
        "method"
      ],
      "title": "StoreFileLoader",
      "type": "object"
    },
    "TestConf": {
      "properties": {
        "min_row_count": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Minimal number of rows to expect"
        },
        "max_row_count": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Maximal number of rows to expect"
        }
      },
      "title": "TestConf",
      "type": "object"
    }
  },
  "additionalProperties": true,
  "properties": {
    "version": {
      "const": "kgsteward_yaml_2",
      "description": "This mandatory fixed value determines the admissible YAML syntax",
      "title": "YAML syntax version",
      "type": "string"
    },
    "server": {
      "discriminator": {
        "mapping": {
          "fuseki": "#/$defs/FusekiConf",
          "graphdb": "#/$defs/GraphDBConf",
          "rdf4j": "#/$defs/RDF4JConf"
        },
        "propertyName": "brand"
      },
      "oneOf": [
        {
          "$ref": "#/$defs/GraphDBConf"
        },
        {
          "$ref": "#/$defs/RDF4JConf"
        },
        {
          "$ref": "#/$defs/FusekiConf"
        }
      ],
      "title": "Server"
    },
    "file_loader": {
      "anyOf": [
        {
          "$ref": "#/$defs/SparqlFileLoader"
        },
        {
          "$ref": "#/$defs/StoreFileLoader"
        },
        {
          "$ref": "#/$defs/HttpServerFileLoader"
        },
        {
          "$ref": "#/$defs/RiotChunkStoreFileLoader"
        }
      ],
      "title": "File Loader"
    },
    "url_loader": {
      "anyOf": [
        {
          "$ref": "#/$defs/SparqlUrlLoader"
        },
        {
          "$ref": "#/$defs/CurlRiotChunkStoreUrlLoader"
        }
      ],
      "title": "Url Loader"
    },
    "dataset": {
      "description": "Mandatory key to specify the content of the knowledge graph in the triplestore.",
      "items": {
        "$ref": "#/$defs/DatasetConf"
      },
      "title": "Knowledge Graph content",
      "type": "array"
    },
    "context_base_IRI": {
      "description": "Base IRI to construct the graph context. In doubt, give `http://example.org/context/` a try.",
      "title": "context base IRI",
      "type": "string"
    },
    "queries": {
      "anyOf": [
        {
          "items": {
            "$ref": "#/$defs/QueryConf"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "description": "Structured list of SPARQL queries.",
      "title": "Collection of SPARQL queries"
    },
    "validations": {
      "anyOf": [
        {
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "A list of paths to files contining SPARQL queries used to validate the repository. Wildcards `*` can be used. By convention, a valid result should be empty, i.e. no row is returned. Failed results should return rows permitting to diagnose the problems.",
      "title": "Validation queries"
    }
  },
  "required": [
    "version",
    "server",
    "file_loader",
    "url_loader",
    "dataset",
    "context_base_IRI",
    "queries"
  ],
  "title": "KGStewardConf",
  "type": "object",
  "description": "Top level YAML keys"
}